
@article{klarin_decade-long_2020,
	title = {The decade-long cryptocurrencies and the blockchain rollercoaster: {Mapping} the intellectual structure and charting future directions},
	volume = {51},
	issn = {0275-5319},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV05T8MwFLaqDoiFG1Eu-QcQmsM5zAYtUZdOlIUliq8SQEmVwsDOD-c9J4GCEAOsiZ3Efi_vsL_3mZDAP3edbzYhij3tcuXzMDQqZ1yA55ORjIRrRJwnWDc8vg3v0ng6SSY9MupKYxBl2bqCxsRb491eGbaTO1wUxfAG999QoSAiQWIprP8F44wov3R89ZGDgfuzGwvQ2MHWHRGRhXzVhcgtrSfHK649e_4HZ7XigNJNMu--9fNMBSmXK3jsjtjxn-PZIhttjEovm3bbpKfLHbLWQeR3yRvoFlUakfXOU1XOqaxfF8-VtFRP8JIlzUtFIbKkAlzlo7zPi5LWuEJRyypHZoYLOs2RGGJuWxUrpSy0IbR9qbV9CBaFITCbNtwntBkO_ip7ZJZez0YTpz3NwZEcDJkJpVEiMMpEkMyLiHHfT0KYagYBBQ_hlmZGSshghCuMkoZxFceeSCCiYCwQwT7pl1WpDwiVDJPAgEEXxZSKhedpbnzpuUJ7LJYDctZJLVs0nB1ZB2Z7yKyQMxRy1gh5QKJOstkX2WTgVX7rePjXjkdk3ce03a7kHJM-TKw-IX3Um1Orru-cXPua},
	doi = {10.1016/j.ribaf.2019.101067},
	abstract = {Recent advances in science mapping allowed to analyze the entire intellectual structure of blockchain and cryptocurrencies in business-related disciplines to identify 174 academic articles as well as 1482 practitioner-oriented articles published since the inception of cryptocurrencies in 2008 to highlight key trends of the published outputs. The results demonstrate academic research done by 389 authors in 296 organizations based in 50 countries that only just initiated the conversation on four major streams of the literature— and . When comparing academic scholarship to practitioner-oriented literature, the results demonstrate that practitioners discussed investor-related themes, cryptocurrency intrinsic value, political-economic sphere, and the impact of cryptocurrency and blockchain technologies on the wider society in greater detail. As a result, a number of themes are identified and discussed that could align academic and practitioner interests and provide guidance for further research in this important field.},
	number = {Journal Article},
	journal = {Research in International Business and Finance},
	author = {Klarin, Anton},
	year = {2020},
	keywords = {Bibliometrics, Bitcoin, Blockchain, Blockchain ecosystem, Cryptocurrency, Science mapping},
	pages = {101067}
}

@article{porayska-pomsta_blending_2018,
	title = {Blending {Human} and {Artificial} {Intelligence} to {Support} {Autistic} {Children}'s {Social} {Communication} {Skills}},
	volume = {25},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwhZ27T8MwEMZPqBMMPAqIt25jSjG249hjKVRl6ARdWCrHDwnRpoiW_x87cWlASKyR5UQ-2_cp9v0-AEZ7JPu1J6iQZ5wkhijpSuW5saSgUirNS6fKGq13P8lfhsV4JEcbdrSdhV7n9YG-ScjqnvHzeHjKaBGUfA0CZTx6NvQH4-8t-LYQvKmQDXI_v0ltYwIy81b6GO7BeF2Es3FEMGbZuk3dwjL-_zX7sJt0JPabwB_Alqu6sLf2aMC0ZLuw0wIOHoK7C0kmZiusf96jrmzdRYORwMcWnxNXC4yWn0GeYz_MzshzxkEq_b5eYlPXiz8KTPDp7XU2Wx7BZPjwPBhlyWghi44uImOKee0j_Itp54QXlEtmvSLGWspDwHJaWMOpEZ54acswurkTTEutmNZOsWPoVIvKnQB65qVyQUcK77gWUX8UsRkLb_KGl6fQDWM4fW9QGtM0bmd_Pj2H7TBtZLw8QskFdFYfn-4SOjFAV3W8vwClILEu},
	doi = {10.1145/3271484},
	abstract = {This article examines the educational efficacy of a learning environment in which children diagnosed with Autism Spectrum Conditions (ASC) engage in social interactions with an artificially intelligent (AI) virtual agent and where a human practitioner acts in support of the interactions. A multi-site intervention study in schools across the UK was conducted with 29 children with ASC and learning difficulties, aged 4--14 years old. For reasons related to data completeness and amount of exposure to the AI environment, data for 15 children was included in the analysis. The analysis revealed a significant increase in the proportion of social responses made by ASC children to human practitioners. The number of initiations made to human practitioners and to the virtual agent by the ASC children also increased numerically over the course of the sessions. However, due to large individual differences within the ASC group, this did not reach significance. Although no evidence of transfer to the real-world post-test was shown, anecdotal evidence of classroom transfer was reported. The work presented in this article offers an important contribution to the growing body of research in the context of AI technology design and use for autism intervention in real school contexts. Specifically, the work highlights key methodological challenges and opportunities in this area by leveraging interdisciplinary insights in a way that (i) bridges between educational interventions and intelligent technology design practices, (ii) considers the design of technology as well as the design of its use (context and procedures) on par with one another, and (iii) includes design contributions from different stakeholders, including children with and without ASC diagnosis, educational practitioners, and researchers.},
	number = {6},
	journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
	author = {Porayska-Pomsta, Kaśka and Alcorn, Alyssa and Avramides, Katerina and Beale, Sandra and Bernardini, Sara and Foster, Mary and Frauenberger, Christopher and Good, Judith and Guldberg, Karen and Keay-Bright, Wendy and Kossyvaki, Lila and Lemon, Oliver and Mademtzi, Marilena and Menzies, Rachel and Pain, Helen and Rajendran, Gnanathusharan and Waller, Annalu and Wass, Sam and Smith, Tim},
	year = {2018},
	keywords = {artificially intelligent agent, Autism, intelligent learning environments, neurodiversity, social communication},
	pages = {1--35}
}

@article{miller_explanation_2019,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {0004-3702},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV07T8MwELaqTCyUpygveWMKjeMkjtkKJWoHNrqwWLaboDCEqin_n7vEhoKQkGBM5CSOz7n77vLdHSE8vo7CbzpBMsDN3ES2WoL9ZsxIm-dlVHFAE6mtMMQ7XaRPhXiY5bMBufOpMciydKagV_Gd8nZnxm5xx6u6xpRfLNPTmXyADDnm_4JyRpZfMb39UM5gj10TvSTE0T6brqN8dYn7SLBkeVfRE3vM_mytAk-dc4aoGJJnP-fP3grWtlu8bF_g8Z_vtUd2HValk37cPhmUzQEZ-j4Q1KmFQzJHIp_uw4q0bijeuC9MQeutip83dN60GAtoKSa1UICetA_ZUzel9ogsivvHu1noWjSEYNdSFpaAx5gGTFQlJpMC0ZzmIE8uE_AlwXWU4I7E3MYGkVQi0SfWaVYxboSWS82PSdC8NuUJoZFlSwFgsypLllRxZsCX0zbRJolMKowZkdCLQq36ShzKU9ReVC86haJTEf5SFyMivLzUl6VWYCx-ufIKxavwE9-stdUuUwHmicWy1ARBcJ5xIU___IwzsgNHsud_n5Ngs34rL0iAW-ay27HvJ873Tg},
	doi = {10.1016/j.artint.2018.07.007},
	abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a 'good' explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
	number = {Journal Article},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	year = {2019},
	keywords = {Explainability, Explainable AI, Explanation, Interpretability, Philosophy, School construction, Set (Psychology), Transparency},
	pages = {1--38}
}

@article{miller_explanation_2019-1,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {0004-3702},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV07T8MwELaqTCyUpygveWMKjeMkjtkKJWoHNrqwWLaboDCEqin_n7vEhoKQkGBM5CSOz7n77vLdHSE8vo7CbzpBMsDN3ES2WoL9ZsxIm-dlVHFAE6mtMMQ7XaRPhXiY5bMBufOpMciydKagV_Gd8nZnxm5xx6u6xpRfLNPTmXyADDnm_4JyRpZfMb39UM5gj10TvSTE0T6brqN8dYn7SLBkeVfRE3vM_mytAk-dc4aoGJJnP-fP3grWtlu8bF_g8Z_vtUd2HValk37cPhmUzQEZ-j4Q1KmFQzJHIp_uw4q0bijeuC9MQeutip83dN60GAtoKSa1UICetA_ZUzel9ogsivvHu1noWjSEYNdSFpaAx5gGTFQlJpMC0ZzmIE8uE_AlwXWU4I7E3MYGkVQi0SfWaVYxboSWS82PSdC8NuUJoZFlSwFgsypLllRxZsCX0zbRJolMKowZkdCLQq36ShzKU9ReVC86haJTEf5SFyMivLzUl6VWYCx-ufIKxavwE9-stdUuUwHmicWy1ARBcJ5xIU___IwzsgNHsud_n5Ngs34rL0iAW-ay27HvJ873Tg},
	doi = {10.1016/j.artint.2018.07.007},
	abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a 'good' explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
	number = {Journal Article},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	year = {2019},
	keywords = {Explainability, Explainable AI, Explanation, Interpretability, Philosophy, School construction, Set (Psychology), Transparency},
	pages = {1--38}
}

@article{miller_explanation_2019-2,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {0004-3702},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV07T8MwELaqTCyUpygveWMKjeMkjtkKJWoHNrqwWLaboDCEqin_n7vEhoKQkGBM5CSOz7n77vLdHSE8vo7CbzpBMsDN3ES2WoL9ZsxIm-dlVHFAE6mtMMQ7XaRPhXiY5bMBufOpMciydKagV_Gd8nZnxm5xx6u6xpRfLNPTmXyADDnm_4JyRpZfMb39UM5gj10TvSTE0T6brqN8dYn7SLBkeVfRE3vM_mytAk-dc4aoGJJnP-fP3grWtlu8bF_g8Z_vtUd2HValk37cPhmUzQEZ-j4Q1KmFQzJHIp_uw4q0bijeuC9MQeutip83dN60GAtoKSa1UICetA_ZUzel9ogsivvHu1noWjSEYNdSFpaAx5gGTFQlJpMC0ZzmIE8uE_AlwXWU4I7E3MYGkVQi0SfWaVYxboSWS82PSdC8NuUJoZFlSwFgsypLllRxZsCX0zbRJolMKowZkdCLQq36ShzKU9ReVC86haJTEf5SFyMivLzUl6VWYCx-ufIKxavwE9-stdUuUwHmicWy1ARBcJ5xIU___IwzsgNHsud_n5Ngs34rL0iAW-ay27HvJ873Tg},
	doi = {10.1016/j.artint.2018.07.007},
	abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a 'good' explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
	number = {Journal Article},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	year = {2019},
	keywords = {Explainability, Explainable AI, Explanation, Interpretability, Philosophy, School construction, Set (Psychology), Transparency},
	pages = {1--38}
}

@article{gheondea-eladi_patient_2019,
	title = {Patient decision aids: a content analysis based on a decision tree structure},
	volume = {19},
	issn = {1472-6947},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NaxsxEBXFh9BLafNB3LRBPRUCTmxJu5J6c5IaB2paSn3pRYw0EvTilLiG_PzM7MpJGii59LILuzpo35M0MzuaJyG0Oh2PnqwJ2SuIaIEGiFbRK3TFo40xF-3RA5c_Xy6bnzO7mLv5o5O_eItYrxbc43im2zwpTYQSMRoHBeIErCpjaxMm8H0c1JhtbFXTCfx7o6Y0J649W5OR68rJPMuajke3fxmlTrv_Xyt0Z3Zmr8Wr6i_Kad-xN-JFXu2KnUXNiO-JL996YVSJ9bAcCb9w_UmC5E3o_AKq7Ihkg4WSWzw05py07DVkNzd5Xyxnn39czEf1hIRRUpa-wCevkWZRwtzV_aE3EckuuXEumYCBFtGQBSI3hwIT7SwFOw3f0URjs9EHYrC6XuVDIVutQftJMZiysSaCzZmIMSm5Uhw0Q3GyhSj87oUwQhdAuDb0eAbCMzCe4XYozhnE-4asYd09ICpDpTI8R-VQfGQKAs-0PzeQoBYMUH9ZsypMG89JSOPUUHzYshRodnDKA1b5erMO5FxadoKNevs_unQkXqpu1PB23XdiQPTk92KwSWl93I04ul5Nv_J1_v0OnPHjJw},
	doi = {10.1186/s12911-019-0840-x},
	abstract = {Abstract Introduction This paper presents the preliminary results of a decision-tree analysis of Patient Decision Aids (PDA). PDAs are online or offline tools used to structure health information, elicit relevant values and emphasize the decision as a process, in ways that help patients make more informed health decisions individually or with relevant others. Method Twenty PDAs are randomly selected from the International Patient Decision Aids Standards (IPDAS) (https://decisionaid.ohri.ca/AZlist.html) approved list. An evaluation tool is built bottom-up and top-down and results are described in terms of communicating uncertainty, completeness of the decision tree, ambiguous or misleading phrasing, overall strategies suggested within personal stories. Results Twelve of the analyzed PDAs had branches of the decision tree which were not discussed in the tool and 6 had logically ambiguous phrasing. Many tools included dichotomous options, when the option range was wider. Several options were clustered within the “Do not take/Do not do” option and thus the PDA failed to provide all comparisons necessary to make a decision. Some tools employ expressions that do not differentiate between lack of information and known negative effects. Other tools provide unequal amounts or non-comparable bits of information about the options. Conclusion These results indicate a very loose range of interpretations of what constitutes an option, a treatment, and a treatment option. It thus emphasizes a gap between theory and practice in the evaluation of PDAs. Future developments of PDA evaluation tools should keep track of missing decision tree branches, accurate communication of uncertainty, ambiguity, and lack of knowledge and consider using measures for evaluating the completeness of the option spectrum at an agreed period in time.;INTRODUCTIONThis paper presents the preliminary results of a decision-tree analysis of Patient Decision Aids (PDA). PDAs are online or offline tools used to structure health information, elicit relevant values and emphasize the decision as a process, in ways that help patients make more informed health decisions individually or with relevant others. METHODTwenty PDAs are randomly selected from the International Patient Decision Aids Standards (IPDAS) ( https://decisionaid.ohri.ca/AZlist.html ) approved list. An evaluation tool is built bottom-up and top-down and results are described in terms of communicating uncertainty, completeness of the decision tree, ambiguous or misleading phrasing, overall strategies suggested within personal stories. RESULTSTwelve of the analyzed PDAs had branches of the decision tree which were not discussed in the tool and 6 had logically ambiguous phrasing. Many tools included dichotomous options, when the option range was wider. Several options were clustered within the "Do not take/Do not do" option and thus the PDA failed to provide all comparisons necessary to make a decision. Some tools employ expressions that do not differentiate between lack of information and known negative effects. Other tools provide unequal amounts or non-comparable bits of information about the options. CONCLUSIONThese results indicate a very loose range of interpretations of what constitutes an option, a treatment, and a treatment option. It thus emphasizes a gap between theory and practice in the evaluation of PDAs. Future developments of PDA evaluation tools should keep track of missing decision tree branches, accurate communication of uncertainty, ambiguity, and lack of knowledge and consider using measures for evaluating the completeness of the option spectrum at an agreed period in time.;This paper presents the preliminary results of a decision-tree analysis of Patient Decision Aids (PDA). PDAs are online or offline tools used to structure health information, elicit relevant values and emphasize the decision as a process, in ways that help patients make more informed health decisions individually or with relevant others. Twenty PDAs are randomly selected from the International Patient Decision Aids Standards (IPDAS) (https://decisionaid.ohri.ca/AZlist.html) approved list. An evaluation tool is built bottom-up and top-down and results are described in terms of communicating uncertainty, completeness of the decision tree, ambiguous or misleading phrasing, overall strategies suggested within personal stories. Twelve of the analyzed PDAs had branches of the decision tree which were not discussed in the tool and 6 had logically ambiguous phrasing. Many tools included dichotomous options, when the option range was wider. Several options were clustered within the "Do not take/Do not do" option and thus the PDA failed to provide all comparisons necessary to make a decision. Some tools employ expressions that do not differentiate between lack of information and known negative effects. Other tools provide unequal amounts or non-comparable bits of information about the options. These results indicate a very loose range of interpretations of what constitutes an option, a treatment, and a treatment option. It thus emphasizes a gap between theory and practice in the evaluation of PDAs. Future developments of PDA evaluation tools should keep track of missing decision tree branches, accurate communication of uncertainty, ambiguity, and lack of knowledge and consider using measures for evaluating the completeness of the option spectrum at an agreed period in time.;},
	number = {1},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Gheondea-Eladi, Alexandra},
	year = {2019},
	keywords = {Analysis, Decision tree analysis, Decision-making, Health aspects, IPDAS, Patient decision aids, Patients},
	pages = {137--137}
}

@article{zhang_detecting_2019,
	title = {Detecting fake news for reducing misinformation risks using analytics approaches},
	volume = {279},
	issn = {0377-2217},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Nj9MwEB2tclgtB7pbvsqyK5_ggEKTOLGd49Ju1ctKSNALFyt27KpFaqu2_H9mGpttQXCAWz4mieOxZ17i52cAXnzI0l9igjSYGCtlstYb74QwmRe2UrVQokTAQH8KxrPq60Q-TNX0DEZxagyxLEMq6EL8IXiHI8NQucPNYjH8nHEEigiwEZEg6pU0wRyDM7H8JuOPP4Mz5e_DwIKUKVmHeTQd5cst1yQRmtcHSc-i-FOuSiJxLqShSQ_mscSPKytYuztiZUd5x_98q0t4GpAqu-vsruDMrfpwHonyfejFBSFYiA99eHKkbvgMPo0djVDgNvPNN8cIwDPEyGxLcrF0GNtYEG6l5sGI5r5j9IA5a0gshSSkWVQ9d7vnMJvcfxlN07CAQ2qxY6vU-rLKrDWtU4YLLrO2koVRVorG8FKJ1nuZt45gWy1bb_Hzr7WcI-RSPq8N5y8gWa1X7hUw6TDSqLJulC9LPGWEFxLBm6WBYLzfAN5HV-lNp9OhI4FtqcmxmhyricVXFAOoojf1iSM0JpK_XveSXK-pbvbbxuqqRgCGH_RqAO9OzjRhdgOWngS29N2R5dsTy3knL_674et_LOQ1XNAecW5y8QaS_fa7u4GE2uPtoTP8ALnjFcg},
	doi = {10.1016/j.ejor.2019.06.022},
	abstract = {Fake news is playing an increasingly dominant role in spreading misinformation by influencing people's perceptions or knowledge to distort their awareness and decision-making. The growth of social media and online forums has spurred the spread of fake news causing it to easily blend with truthful information. This study provides a novel text analytics--driven approach to fake news detection for reducing the risks posed by fake news consumption. We first describe the framework for the proposed approach and the underlying analytical model including the implementation details and validation based on a corpus of news data. We collect legitimate and fake news, which is transformed from a document based corpus into a topic and event--based representation. Fake news detection is performed using a two-layered approach, which is comprised of detecting fake topics and fake events. The efficacy of the proposed approach is demonstrated through the implementation and validation of a novel FakE News Detection (FEND) system. The proposed approach achieves 92.49\% classification accuracy and 94.16\% recall based on the specified threshold value of 0.6.;Fake news is playing an increasingly dominant role in spreading misinformation by influencing people’s perceptions or knowledge to distort their awareness and decision-making. The growth of social media and online forums has spurred the spread of fake news causing it to easily blend with truthful information. This study provides a novel text analytics–driven approach to fake news detection for reducing the risks posed by fake news consumption. We first describe the framework for the proposed approach and the underlying analytical model including the implementation details and validation based on a corpus of news data. We collect legitimate and fake news, which is transformed from a document based corpus into a topic and event–based representation. Fake news detection is performed using a two-layered approach, which is comprised of detecting fake topics and fake events. The efficacy of the proposed approach is demonstrated through the implementation and validation of a novel ak ews etection ( ) system. The proposed approach achieves 92.49\% classification accuracy and 94.16\% recall based on the specified threshold value of 0.6.;},
	number = {3},
	journal = {European Journal of Operational Research},
	author = {Zhang, Chaowei and Gupta, Ashish and Kauten, Christian and Deokar, Amit V. and Qin, Xiao},
	year = {2019},
	keywords = {Analytics, Classification, Fake news, Text analytics, Topic modeling},
	pages = {1036--1052}
}

@article{she_qos-aware_2019,
	title = {{QoS}-aware cloud service composition: {A} systematic mapping study from the perspective of computational intelligence},
	volume = {138},
	issn = {0957-4174},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3LTsJAFL0hrNyIz4ivzN5U2unbHYINGxcG3LiZzKsEo5RQCL_v3HYqaIwLTbppM5OU3sm5J8M5ZwB8eus63zAhEYEQylNxolTMtaLCD1UQySgw-Jgo3CkYPocvWfw4SkYtGDTWGFRZ2lZQQ3wF3vZJz37c3mI2640NVzDd0VypWcK1wdyAM6r8suH95x8LsVs7qM1gB0dbH00t-dLlBqOIvLTK86Tez71qp_9kHZg2r7o9UkHKckeO3eQ6_vPnHMC-paikX487hJaeH0GnOf6BWDQ4huVTMXb4hi81kW_FWpGyxh2CMnWrBbsjfbINiybvHOMgpqQKtSVobSGGgJLF1vFJiryav17ZXUoy2wkNPYFJ9jAZjBx7hIMjU9zYkkjJNOUyFEgsfUVdoZQhaVwZKiG8VMSe4Nx0yNQNPMlDT0pBRUKloQ0590-hPS_m-gwIV6nQGFajc3S0KB76uYpy6sYikJHmXbhpasUWdVAHaxRsrwwry7CyzI2ZqWwXwqac7EtBmOkkv8w7_-O8C9jDuyoh0r2E9mq51lfQxqVyXS3QD4L39qs},
	doi = {10.1016/j.eswa.2019.07.021},
	abstract = {Cloud service composition builds new value-added services by combining existing single services. However, because of the exuberant growth of cloud services and the varying quality of service (QoS), discovering required services and creating a service composition with certain quality guarantees becomes a significant technical issue and attracts much concern. Computational intelligence techniques are considered to be effective in solving such problems, and researchers have made substantial efforts in this area. Nevertheless, to the best of our knowledge, there is not any systematic research about this issue with a particular focus on computing intelligence. Thus, the current study aims to create a panoramic view of QoS-aware cloud service composition from the perspective of computational intelligence. The objectives of this paper are to (1) investigate the relevant studies on this field; (2) make a comprehensive examination of the literature from different aspects: active researchers, research motivations, QoS parameters, algorithms, datasets, optimization strategies and could layers; (3) identify the areas which need further research. For this, a search protocol has been well defined, and 105 articles from 2009 to 2018 were selected. This study classified these articles into three groups, including non-heuristic, heuristic and meta-heuristic, and then examined the research works from several aspects. The results indicate that reducing response time is the most important motivation for researchers, and meta-heuristic algorithms, especially genetic algorithms, are the most widely used computational intelligence techniques. Besides, the most widely used QoS attributes and datasets are also revealed. Additionally, the study points out there are still some research challenges in this area, such as QoS evaluation in a dynamic environment and inter-service correlations. In general, this study classified and compared the existing computational intelligence techniques; analyzed the research status and identified future research directions. It can provide a basis for both researchers and practitioners who are interested in this area. More significantly, in the field of expert and intelligent systems, this study can assist in the design and development of expert and intelligent systems in enterprises, it can efficiently assist enterprises in business decisions and risk reduction.},
	number = {Journal Article},
	journal = {Expert Systems With Applications},
	author = {She, Qiping and Wei, Xiaochao and Nie, Guihua and Chen, Donglin},
	year = {2019},
	keywords = {Cloud service composition, Computational intelligence techniques, Quality of service (QoS), Systematic mapping study},
	pages = {112804}
}

@article{de_rosa_analytical_2019,
	title = {Analytical games for knowledge engineering of expert systems in support to {Situational} {Awareness}: {The} {Reliability} {Game} case study},
	volume = {138},
	issn = {0957-4174},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV07T8MwELZQJxbeiPLS7ajUSZrYZoNC6MIELCyRn6gMaUVTIUb-OWcnaQtCDCBlSWQrcc767mx_9x0hSXxOe98wgTo3UDF3hmaKZSIVkaVcS-24NJHkPv35-jF9ytndiI_WyLBNjfEsy8YV1BAfwLt50m9-bn86HvfvMVZA74iX8CdHmc__RXD2LL_8-mpxsMBonUGNjXu-dZNHU1O-7OzNSxFFIuh5hhpmP_iqFf-Tb5Ln9lOXJRW0nq3QsVtdx38OZ4tsNCEqXNbttsmaLXfIZlv-ARo02CUfQdAk7IXDsyfbAgbAsNikA7uUOoSJg1BLoIJaOnoG4xJm86mP_qGawP24mjfbknD55hPUEIEvACcxeNJ0LSb-Drf4GtDoeCHI4u6Rh_zmYTjqNRUdelogIKeIIDJVysnUJMZRlxorophZSSWPhYlUzDKtEslorHBtbpnUQjlc8tgo4VQn-6RTTkp7QCCh3CnNNU-4GaRcKmUSJpmKhMEFkMy65Kw1XTGtdTuKltD2UnhDF97QBWUFGrpL0ta6xRf7FOhYful3-Md-R2Td3wXBSHpMOtXr3J6Qjp85p2G-fgJ_Cvxx},
	doi = {10.1016/j.eswa.2019.07.017},
	abstract = {Knowledge Acquisition (KA) methods are of paramount importance in the design of intelligent systems. Research is ongoing to improve their effectiveness and efficiency. appear to be a promising tool to support KA. In fact, in this paper we describe how could be used for Knowledge Engineering of Bayesian networks, through the presentation of the case study of the Reliability Game. This game has been developed with the aim of collecting data on the impact of meta-knowledge about sources of information upon human Situational Assessment in a maritime context. In this paper we describe the computational model obtained from the dataset and how the card positions, which reflect a player belief, can be easily converted in subjective probabilities and used to learn latent constructs, such as the source reliability, by applying the Expectation-Maximisation algorithm.},
	number = {Journal Article},
	journal = {Expert Systems With Applications},
	author = {de Rosa, Francesca and De Gloria, Alessandro and Jousselme, Anne-Laure},
	year = {2019},
	keywords = {Analytical game, Bayesian networks, Expert knowledge, Knowledge acquisition, Parameter learning, Source reliability},
	pages = {112800}
}

@article{rhim_human_2020,
	title = {Human moral reasoning types in autonomous vehicle moral dilemma: {A} cross-cultural comparison of {Korea} and {Canada}},
	volume = {102},
	issn = {0747-5632},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1NT4NAEJ00PfVitWr8zvwB5GMLuHqqrYTEeFIvXsiygK1JobHFxH_vzpal1WO9boaFHeA9mH0zA8C8a8f6gwkeE7kvQ5a6AReKQiQLFREVmVu4bCgKCvFOXv23KHyKb-IOjE1qDKksGypYQ7wG72bEbpxrL2Yz-5kqwfsBU28g0w2ZFCwrcCaVXzS536g-fN1uk4wtsjYbnVryJacpib24LupJObUtP21xTtSHd3N5mzYKUi63JNimluM_l7APe81nKY7WdgfQycsB9E3LB2wQYAC9FjC_D2GhdwBwTkn-SOJ2HdpFiuoucVaiqFeUMlHVS_zKpzRxY5spKJrPxS2OULO0Zep_oGzbImJV4GOlZkVRZqiLKIgjuIseXsaxZRyW_FpyovA5MXqyj0T5OSE_J9QB03XYMXTLqsxPADkXvpMKyXPhDwsWcNcLZMqlGgt4IMNTGO5yhrPdDjuHnke_1zricgHd1WedX0KXbvaVfqx-AFFC4V8},
	doi = {10.1016/j.chb.2019.08.010},
	abstract = {The widespread of Autonomous Vehicle (AV) promises a transportation system revolution. Despite its potential benefits, there has been an unsolved discussion of how AV should behave during unavoidable crash situations, which is known as the Moral Dilemma of AV. The goal of this study is to investigate how AV Morality can be designed to align with human values by observing human moral reasoning process, which could be applicable for AV Moral Dilemma scenarios. To do that, we used an exploratory sequential mixed-research methodology to compare human moral reasoning types from two cultures: Korea, a highly collectivist culture, and Canada, a typical individualist culture. First, unavoidable crash scenarios that reflect the complex real-world crash contexts were developed. Second, a moral thought experiment in the form of in-depth interviews was conducted for both cultures (N = 70, Koreans = 33, Canadians = 37). Finally, K-means clustering analysis was conducted. As a result, three human moral reasoning types (Moral Altruist, Moral Non-determinist, and Moral-Deontologist) were defined. The study results reduce abstractness of AV morality by defining distinct moral decision-making patterns which are described by moral value. The findings provide guidelines for designing culture-specific moral behaviors, provide guidelines for AV practitioners, and increase AV morality transparency for the public.},
	number = {Journal Article},
	journal = {Computers in Human Behavior},
	author = {Rhim, Jimin and Lee, Gi-bbeum and Lee, Ji-Hyun},
	year = {2020},
	keywords = {Autonomous vehicle, Cross-cultural comparison, Ethical decision-making, Mixed-methods, Moral dilemma},
	pages = {39--56}
}

@article{linkevicius_linking_2019,
	title = {Linking forest policy issues and decision support tools in {Europe}},
	volume = {103},
	issn = {1389-9341},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV07T8MwELaqDIiFN6K85I0pNM_GGUtL1AEm6MJiOX6gIpRWTfv_uYttXhJCgjGWoyS-yz10d99HSJpcR-E3myBFluosNiIyKtUiyzUzQyY0RBdJaTTOKk9m-VNV3E_ZtEfGfjQGuyydK7AmvjPebmXgDnewnM8HD1hxK8Emx6CzSKkMZhmMM3b5VZOb98JCEXWMybg5xN1-mq5r-TIIHoz1iJhZOM_sJ28V-NY554iqXfLs3_mDW0HK9lNftgd4_Od37ZEdF6vSkd23T3q6OSBbSOaJDHGHZHRniReo6ZbossMYpp0oWyoaRZVj8KHtZomBPl0vFq8tnTfUVgGOyKy6fRxPQ0fJEMoUkrNQRRJSpKSuS0i8UrCThWAqVsxkhcyHxtQaxKpiprRKwDsqHFQdJkUNSYmUGFsek6BZNPqEUKNTUSIoqRZRphEEJwJ9iDMplIgNY30S-qPnS4u8wX1L2gu3ouIoKh7lHETVJ4WXD_9ytBycwy93XqE4Of7S65WQwk0mwHsiOBYfQZCWYoG-PP3zM87INlyVtsnsnATr1UZfkABV5LLT0DfSePQh},
	doi = {10.1016/j.forpol.2018.05.014},
	abstract = {* The barriers to the more widespread use of DS tools in forest policy analysis are technical, but some are also political. While very many decision-support (DS) tools (i.e. models and decision support systems (DSS)) have been developed to address forest management problems in Europe, the use of such tools in supporting forest policy processes remains limited. Additionally, while there has been very limited sharing of these tools between European countries, there may be an untapped potential for both users and developers in this area.;While very many decision-support (DS) tools (i.e. models and decision support systems (DSS)) have been developed to address forest management problems in Europe, the use of such tools in supporting forest policy processes remains limited. Additionally, while there has been very limited sharing of these tools between European countries, there may be an untapped potential for both users and developers in this area. This paper focuses on improving understanding and capacities in the use of forest DS tools for decision making by identifying major forest policy areas, tools available to support them, compatibility of existing tools with the requirements of forest policy areas, potential areas where tools may be shared between countries and factors limiting the use of DS tools in forest policy. Data collection was based on expert interviews. The questionnaire, which comprised a combination of open- and close-ended questions, was forwarded to experts via email. Expert interviews were completed via Skype with the input of one policy specialist and one modeller/decision support specialist from each country. This study categorised key forest policy areas and the DS tools available to support them. Almost one third of these forest policy areas were not addressed by any DS tool. The analysis also revealed that DS tools are mainly developed to assist scientists and policy decision makers to address smaller spatial scales, that they are more orientated to single decision makers with a predominant focus on market wood products. In addition, through an attribute-matching exercise, the DS tools that could potentially be used in other countries to support similar forest policy areas were also identified. Interviews highlighted some of the reasons why DS tools are seldom used in policy making processes; these include a lack of trust in the actual use of the tools as well as a perception of inadequacy for the specifics of real policy process. This research provides a detailed overview of existing DS tools and the forest policy areas that they address. It further provides information on how to address or reduce the gap between DS tools functionalities and requirements from policy makers.;},
	number = {Journal Article},
	journal = {Forest Policy and Economics},
	author = {Linkevičius, Edgaras and Borges, José G. and Doyle, Marie and Pülzl, Helga and Nordström, Eva-Maria and Vacik, Harald and Brukas, Vilis and Biber, Peter and Teder, Meelis and Kaimre, Paavo and Synek, Michal and Garcia-Gonzalo, Jordi},
	year = {2019},
	keywords = {Expert interview, Forest decision support system, Forest management, Forest policy, Forest policy area, Model, Simulator},
	pages = {4--16}
}

@article{tanaka_disease_2018,
	title = {Disease vocabulary size as a surrogate marker for physicians' disease knowledge volume},
	volume = {13},
	issn = {1932-6203},
	url = {http://uccs.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1Lb9QwEB61y4ULUF4Nj5U5FQ7ZzTpO4hwQitpd9gAUIcqBS-Q4MUJVkyhukODXM5M42xYJiQOXSCtZm4xnPPPZM_4GIOSLwP_DJ2gZojfmGuN5wQ1GWVOJkmv8kcaqMgMBzln0dZO838rtHrydrsYMxe_kKgenrdrWLstGL7MoTkSK9rZaZqcf1m-uNdPoXxPb85jUtPtwCwNQMFzsy04nD41rfMhhEnbxYx6E7kpdmKyWToOLtqmrBUKpNIpWN0KWc9yzFl_yd1Q6RKfNXTi_EmRquKC1vVasPbE-_gdh78EdB2JZNlrdAexV9X04cG7CspeOy_rVA_hyMiaA2A-MmQWVvP5k9vuviinLFLN91zV0jscuqEqoY4ig2e6sxR4xlz5iu5M_NnrTh3C2WX8-3vqulYOvRSLQpQqEKUXFhQxirVGaSGkTp7JIy6QsAyNikZaEVYMilcpIVSgTmSIhurUoreLwEcxqVMkhMNwgljyVckVcZEZEskBtGqFC3PooNCsP_ElbeTsyduRD2i7Bnc44PzlpN3fa9WBOc54TGUZN1TbfVG9tfjXrHhy5Aaa57JRW7uIC_gdxZ90YeUhmMb3G5hzxNAImlN2DF5Op5LiAKSuj6qrpxzHUYyBKPHg82tDuu0Nq-ojiPfnnT3gKtxHSSSq44ckzmF12ffUcZmR1c9jffHw3H5YCPdcZPbeffgMnvxm5},
	doi = {10.1371/journal.pone.0209551},
	abstract = {OBJECTIVERecognizing what physicians know and do not know about a particular disease is one of the keys to designing clinical decision support systems, since these systems can fulfill complementary role by recognizing this boundary. To our knowledge, however, no study has attempted to quantify how many diseases physicians actually know and thus the boundary is unclear. This study explores a method to solve this problem by investigating whether the vocabulary assessment techniques developed in the linguistics field can be applied to assess physicians' knowledge.METHODSThe test design required us to pay special attention to disease knowledge assessment. First, to avoid imposing unnecessary burdens on the physicians, we chose a self-assessment questionnaire that was straightforward to fill out. Second, to prevent overestimation, we used a "pseudo-word" approach: fictitious diseases were included in the questionnaire, and positive responses to them were penalized. Third, we used paper-based tests, rather than computer-based ones, to further prevent participants from cheating by using a search engine. Fourth, we selectively used borderline diseases, i.e., diseases that physicians might or might not know about, rather than well-known or little-known diseases, in the questionnaire.RESULTSWe collected 102 valid answers from 109 physicians who attended the seminars we conducted. On the basis of these answers, we estimated that the average physician knew of 2008 diseases (95\% confidence interval: (1939, 2071)). This preliminary estimation agrees with the guideline for the national license examination in Japan, suggesting that this vocabulary assessment was able to evaluate physicians' knowledge. The survey included physicians with various backgrounds, but there were no significant differences between subgroups. Other implication for researches on clinical decision support and limitation of the sampling method adopted in this study are also discussed, toward more rigorous estimation in future surveys.;The test design required us to pay special attention to disease knowledge assessment. First, to avoid imposing unnecessary burdens on the physicians, we chose a self-assessment questionnaire that was straightforward to fill out. Second, to prevent overestimation, we used a "pseudo-word" approach: fictitious diseases were included in the questionnaire, and positive responses to them were penalized. Third, we used paper-based tests, rather than computer-based ones, to further prevent participants from cheating by using a search engine. Fourth, we selectively used borderline diseases, i.e., diseases that physicians might or might not know about, rather than well-known or little-known diseases, in the questionnaire.;Recognizing what physicians know and do not know about a particular disease is one of the keys to designing clinical decision support systems, since these systems can fulfill complementary role by recognizing this boundary. To our knowledge, however, no study has attempted to quantify how many diseases physicians actually know and thus the boundary is unclear. This study explores a method to solve this problem by investigating whether the vocabulary assessment techniques developed in the linguistics field can be applied to assess physicians' knowledge. The test design required us to pay special attention to disease knowledge assessment. First, to avoid imposing unnecessary burdens on the physicians, we chose a self-assessment questionnaire that was straightforward to fill out. Second, to prevent overestimation, we used a "pseudo-word" approach: fictitious diseases were included in the questionnaire, and positive responses to them were penalized. Third, we used paper-based tests, rather than computer-based ones, to further prevent participants from cheating by using a search engine. Fourth, we selectively used borderline diseases, i.e., diseases that physicians might or might not know about, rather than well-known or little-known diseases, in the questionnaire. We collected 102 valid answers from 109 physicians who attended the seminars we conducted. On the basis of these answers, we estimated that the average physician knew of 2008 diseases (95\% confidence interval: (1939, 2071)). This preliminary estimation agrees with the guideline for the national license examination in Japan, suggesting that this vocabulary assessment was able to evaluate physicians' knowledge. The survey included physicians with various backgrounds, but there were no significant differences between subgroups. Other implication for researches on clinical decision support and limitation of the sampling method adopted in this study are also discussed, toward more rigorous estimation in future surveys.;Objective Recognizing what physicians know and do not know about a particular disease is one of the keys to designing clinical decision support systems, since these systems can fulfill complementary role by recognizing this boundary. To our knowledge, however, no study has attempted to quantify how many diseases physicians actually know and thus the boundary is unclear. This study explores a method to solve this problem by investigating whether the vocabulary assessment techniques developed in the linguistics field can be applied to assess physicians’ knowledge. Methods The test design required us to pay special attention to disease knowledge assessment. First, to avoid imposing unnecessary burdens on the physicians, we chose a self-assessment questionnaire that was straightforward to fill out. Second, to prevent overestimation, we used a “pseudo-word” approach: fictitious diseases were included in the questionnaire, and positive responses to them were penalized. Third, we used paper-based tests, rather than computer-based ones, to further prevent participants from cheating by using a search engine. Fourth, we selectively used borderline diseases, i.e., diseases that physicians might or might not know about, rather than well-known or little-known diseases, in the questionnaire. Results We collected 102 valid answers from 109 physicians who attended the seminars we conducted. On the basis of these answers, we estimated that the average physician knew of 2008 diseases (95\% confidence interval: (1939, 2071)). This preliminary estimation agrees with the guideline for the national license examination in Japan, suggesting that this vocabulary assessment was able to evaluate physicians’ knowledge. The survey included physicians with various backgrounds, but there were no significant differences between subgroups. Other implication for researches on clinical decision support and limitation of the sampling method adopted in this study are also discussed, toward more rigorous estimation in future surveys.;},
	number = {12},
	journal = {PloS one},
	author = {Tanaka, Hiroaki and Ueda, Kazuhiro and Watanuki, Satoshi and Watari, Takashi and Tokuda, Yasuharu and Okumura, Takashi},
	year = {2018},
	keywords = {Analysis of Variance, Artificial intelligence, Bioinformatics, Confidence intervals, Decision making, Decision support systems, Decision Support Systems, Clinical, Diseases, Educational aspects, Humans, Index Medicus, International conferences, Japan, Knowledge, Knowledge Bases, Linguistics, Medical personnel, Medicine, Physicians, Physicians - standards, Public health, Questionnaires, Research, Search engines, Self evaluation, Self-assessment, Studies, Subgroups, Support systems, Surveys, Surveys and Questionnaires, Test procedures, Usage, Vocabulary, Vocabulary tests},
	pages = {e0209551--e0209551}
}

@article{rigas_managing_2015,
	title = {Managing {Electric} {Vehicles} in the {Smart} {Grid} {Using} {Artificial} {Intelligence}: {A} {Survey}},
	volume = {16},
	abstract = {Along with the development of smart grids, the wide adoption of electric vehicles (EVs) is seen as a catalyst to the reduction of CO 2 emissions and more intelligent transportation systems. In particular, EVs augment the grid with the ability to store energy at some points in the network and give it back at others and, therefore, help optimize the use of energy from intermittent renewable energy sources and let users refill their cars in a variety of locations. However, a number of challenges need to be addressed if such benefits are to be achieved. On the one hand, given their limited range and costs involved in charging EV batteries, it is important to design algorithms that will minimize costs and, at the same time, avoid users being stranded. On the other hand, collectives of EVs need to be organized in such a way as to avoid peaks on the grid that may result in high electricity prices and overload local distribution grids. In order to meet such challenges, a number of technological solutions have been proposed. In this paper, we focus on those that utilize artificial intelligence techniques to render EVs and the systems that manage collectives of EVs smarter. In particular, we provide a survey of the literature and identify the commonalities and key differences in the approaches. This allows us to develop a classification of key techniques and benchmarks that can be used to advance the state of the art in this space.},
	language = {English},
	number = {4},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Rigas, Emmanouil S. and Ramchurn, Sarvapali D. and Bassiliades, Nick},
	year = {2015},
	keywords = {Artificial intelligence, Artificial intelligence (AI), Batteries, electric vehicles (EVs), Heuristic algorithms, Routing, smart grid, Smart grids, Supercapacitors, Vehicles},
	pages = {1619--1635}
}

@article{shahid_applications_2019,
	title = {Applications of artificial neural networks in health care organizational decision-making: {A} scoping review},
	volume = {14},
	abstract = {Health care organizations are leveraging machine-learning techniques, such as artificial neural networks (ANN), to improve delivery of care at a reduced cost. Applications of ANN to diagnosis are well-known; however, ANN are increasingly used to inform health care management decisions. We provide a seminal review of the applications of ANN to health care organizational decision-making. We screened 3,397 articles from six databases with coverage of Health Administration, Computer Science and Business Administration. We extracted study characteristics, aim, methodology and context (including level of analysis) from 80 articles meeting inclusion criteria. Articles were published from 1997-2018 and originated from 24 countries, with a plurality of papers (26 articles) published by authors from the United States. Types of ANN used included ANN (36 articles), feed-forward networks (25 articles), or hybrid models (23 articles); reported accuracy varied from 50\% to 100\%. The majority of ANN informed decision-making at the micro level (61 articles), between patients and health care providers. Fewer ANN were deployed for intra-organizational (meso- level, 29 articles) and system, policy or inter-organizational (macro- level, 10 articles) decision-making. Our review identifies key characteristics and drivers for market uptake of ANN for health care organizational decision-making to guide further adoption of this technique.},
	language = {English},
	number = {2},
	journal = {PloS one},
	author = {Shahid, Nida and Rappon, Tim and Berta, Whitney},
	year = {2019},
	keywords = {Analysis, Artificial intelligence, Artificial neural networks, Business administration, Decision making, Decision-making, Feedforward, Global health, Growth rate, Health care, Health care industry, Health care policy, Learning algorithms, Learning theory, Machine learning, Medical care, Model accuracy, Neural networks, Operations management, Research, Researchers, System theory, Trends},
	pages = {e0212356--e0212356}
}